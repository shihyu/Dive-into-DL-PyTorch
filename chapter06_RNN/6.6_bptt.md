# 6.6 通過時間反向傳播

在前面兩節中，如果不裁剪梯度，模型將無法正常訓練。為了深刻理解這一現象，本節將介紹循環神經網絡中梯度的計算和存儲方法，即通過時間反向傳播（back-propagation through time）。

我們在3.14節（正向傳播、反向傳播和計算圖）中介紹了神經網絡中梯度計算與存儲的一般思路，並強調正向傳播和反向傳播相互依賴。正向傳播在循環神經網絡中比較直觀，而通過時間反向傳播其實是反向傳播在循環神經網絡中的具體應用。我們需要將循環神經網絡按時間步展開，從而得到模型變量和參數之間的依賴關係，並依據鏈式法則應用反向傳播計算並存儲梯度。


## 6.6.1 定義模型

簡單起見，我們考慮一個無偏差項的循環神經網絡，且激活函數為恆等映射（$\phi(x)=x$）。設時間步 $t$ 的輸入為單樣本 $\boldsymbol{x}_t \in \mathbb{R}^d$，標籤為 $y_t$，那麼隱藏狀態 $\boldsymbol{h}_t \in \mathbb{R}^h$的計算表達式為

$$
\boldsymbol{h}_t = \boldsymbol{W}_{hx} \boldsymbol{x}_t + \boldsymbol{W}_{hh} \boldsymbol{h}_{t-1},
$$

其中$\boldsymbol{W}_{hx} \in \mathbb{R}^{h \times d}$和$\boldsymbol{W}_{hh} \in \mathbb{R}^{h \times h}$是隱藏層權重參數。設輸出層權重參數$\boldsymbol{W}_{qh} \in \mathbb{R}^{q \times h}$，時間步$t$的輸出層變量$\boldsymbol{o}_t \in \mathbb{R}^q$計算為

$$
\boldsymbol{o}_t = \boldsymbol{W}_{qh} \boldsymbol{h}_{t}.
$$

設時間步$t$的損失為$\ell(\boldsymbol{o}_t, y_t)$。時間步數為$T$的損失函數$L$定義為

$$
L = \frac{1}{T} \sum_{t=1}^T \ell (\boldsymbol{o}_t, y_t).
$$

我們將$L$稱為有關給定時間步的數據樣本的目標函數，並在本節後續討論中簡稱為目標函數。


## 6.6.2 模型計算圖

為了可視化循環神經網絡中模型變量和參數在計算中的依賴關係，我們可以繪製模型計算圖，如圖6.3所示。例如，時間步3的隱藏狀態$\boldsymbol{h}_3$的計算依賴模型參數$\boldsymbol{W}_{hx}$、$\boldsymbol{W}_{hh}$、上一時間步隱藏狀態$\boldsymbol{h}_2$以及當前時間步輸入$\boldsymbol{x}_3$。

<div align=center>
<img width="500" src="../img/chapter06/6.6_rnn-bptt.svg"/>
</div>
<div align=center>圖6.3 時間步數為3的循環神經網絡模型計算中的依賴關係。方框代表變量（無陰影）或參數（有陰影），圓圈代表運算符</div>


## 6.6.3 方法

剛剛提到，圖6.3中的模型的參數是 $\boldsymbol{W}_{hx}$, $\boldsymbol{W}_{hh}$ 和 $\boldsymbol{W}_{qh}$。與3.14節（正向傳播、反向傳播和計算圖）中的類似，訓練模型通常需要模型參數的梯度$\partial L/\partial \boldsymbol{W}_{hx}$、$\partial L/\partial \boldsymbol{W}_{hh}$和$\partial L/\partial \boldsymbol{W}_{qh}$。
根據圖6.3中的依賴關係，我們可以按照其中箭頭所指的反方向依次計算並存儲梯度。為了表述方便，我們依然採用3.14節中表達鏈式法則的運算符prod。

首先，目標函數有關各時間步輸出層變量的梯度$\partial L/\partial \boldsymbol{o}_t \in \mathbb{R}^q$很容易計算：

$$\frac{\partial L}{\partial \boldsymbol{o}_t} =  \frac{\partial \ell (\boldsymbol{o}_t, y_t)}{T \cdot \partial \boldsymbol{o}_t}.$$

下面，我們可以計算目標函數有關模型參數$\boldsymbol{W}_{qh}$的梯度$\partial L/\partial \boldsymbol{W}_{qh} \in \mathbb{R}^{q \times h}$。根據圖6.3，$L$通過$\boldsymbol{o}_1, \ldots, \boldsymbol{o}_T$依賴$\boldsymbol{W}_{qh}$。依據鏈式法則，

$$
\frac{\partial L}{\partial \boldsymbol{W}_{qh}} 
= \sum_{t=1}^T \text{prod}\left(\frac{\partial L}{\partial \boldsymbol{o}_t}, \frac{\partial \boldsymbol{o}_t}{\partial \boldsymbol{W}_{qh}}\right) 
= \sum_{t=1}^T \frac{\partial L}{\partial \boldsymbol{o}_t} \boldsymbol{h}_t^\top.
$$


其次，我們注意到隱藏狀態之間也存在依賴關係。
在圖6.3中，$L$只通過$\boldsymbol{o}_T$依賴最終時間步$T$的隱藏狀態$\boldsymbol{h}_T$。因此，我們先計算目標函數有關最終時間步隱藏狀態的梯度$\partial L/\partial \boldsymbol{h}_T \in \mathbb{R}^h$。依據鏈式法則，我們得到

$$
\frac{\partial L}{\partial \boldsymbol{h}_T} = \text{prod}\left(\frac{\partial L}{\partial \boldsymbol{o}_T}, \frac{\partial \boldsymbol{o}_T}{\partial \boldsymbol{h}_T} \right) = \boldsymbol{W}_{qh}^\top \frac{\partial L}{\partial \boldsymbol{o}_T}.
$$

接下來對於時間步$t < T$, 在圖6.3中，$L$通過$\boldsymbol{h}_{t+1}$和$\boldsymbol{o}_t$依賴$\boldsymbol{h}_t$。依據鏈式法則，
目標函數有關時間步$t < T$的隱藏狀態的梯度$\partial L/\partial \boldsymbol{h}_t \in \mathbb{R}^h$需要按照時間步從大到小依次計算：
$$
\frac{\partial L}{\partial \boldsymbol{h}_t} 
= \text{prod} (\frac{\partial L}{\partial \boldsymbol{h}_{t+1}}, \frac{\partial \boldsymbol{h}_{t+1}}{\partial \boldsymbol{h}_t}) + \text{prod} (\frac{\partial L}{\partial \boldsymbol{o}_t}, \frac{\partial \boldsymbol{o}_t}{\partial \boldsymbol{h}_t} ) = \boldsymbol{W}_{hh}^\top \frac{\partial L}{\partial \boldsymbol{h}_{t+1}} + \boldsymbol{W}_{qh}^\top \frac{\partial L}{\partial \boldsymbol{o}_t}
$$

將上面的遞歸公式展開，對任意時間步$1 \leq t \leq T$，我們可以得到目標函數有關隱藏狀態梯度的通項公式

$$
\frac{\partial L}{\partial \boldsymbol{h}_t} 
= \sum_{i=t}^T {\left(\boldsymbol{W}_{hh}^\top\right)}^{T-i} \boldsymbol{W}_{qh}^\top \frac{\partial L}{\partial \boldsymbol{o}_{T+t-i}}.
$$

由上式中的指數項可見，當時間步數 $T$ 較大或者時間步 $t$ 較小時，目標函數有關隱藏狀態的梯度較容易出現衰減和爆炸。這也會影響其他包含$\partial L / \partial \boldsymbol{h}_t$項的梯度，例如隱藏層中模型參數的梯度$\partial L / \partial \boldsymbol{W}_{hx} \in \mathbb{R}^{h \times d}$和$\partial L / \partial \boldsymbol{W}_{hh} \in \mathbb{R}^{h \times h}$。
在圖6.3中，$L$通過$\boldsymbol{h}_1, \ldots, \boldsymbol{h}_T$依賴這些模型參數。
依據鏈式法則，我們有

$$
\begin{aligned}
\frac{\partial L}{\partial \boldsymbol{W}_{hx}} 
&= \sum_{t=1}^T \text{prod}\left(\frac{\partial L}{\partial \boldsymbol{h}_t}, \frac{\partial \boldsymbol{h}_t}{\partial \boldsymbol{W}_{hx}}\right) 
= \sum_{t=1}^T \frac{\partial L}{\partial \boldsymbol{h}_t} \boldsymbol{x}_t^\top,\\
\frac{\partial L}{\partial \boldsymbol{W}_{hh}} 
&= \sum_{t=1}^T \text{prod}\left(\frac{\partial L}{\partial \boldsymbol{h}_t}, \frac{\partial \boldsymbol{h}_t}{\partial \boldsymbol{W}_{hh}}\right) 
= \sum_{t=1}^T \frac{\partial L}{\partial \boldsymbol{h}_t} \boldsymbol{h}_{t-1}^\top.
\end{aligned}
$$


我們已在3.14節裡解釋過，每次迭代中，我們在依次計算完以上各個梯度後，會將它們存儲起來，從而避免重複計算。例如，由於隱藏狀態梯度$\partial L/\partial \boldsymbol{h}_t$被計算和存儲，之後的模型參數梯度$\partial L/\partial  \boldsymbol{W}_{hx}$和$\partial L/\partial \boldsymbol{W}_{hh}$的計算可以直接讀取$\partial L/\partial \boldsymbol{h}_t$的值，而無須重複計算它們。此外，反向傳播中的梯度計算可能會依賴變量的當前值。它們正是通過正向傳播計算出來的。
舉例來說，參數梯度$\partial L/\partial \boldsymbol{W}_{hh}$的計算需要依賴隱藏狀態在時間步$t = 0, \ldots, T-1$的當前值$\boldsymbol{h}_t$（$\boldsymbol{h}_0$是初始化得到的）。這些值是通過從輸入層到輸出層的正向傳播計算並存儲得到的。


## 小結

* 通過時間反向傳播是反向傳播在循環神經網絡中的具體應用。
* 當總的時間步數較大或者當前時間步較小時，循環神經網絡的梯度較容易出現衰減或爆炸。


------------
> 注：本節與原書基本相同，[原書傳送門](https://zh.d2l.ai/chapter_recurrent-neural-networks/bptt.html)