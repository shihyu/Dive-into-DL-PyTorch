# 10.4 子詞嵌入（fastText）

英語單詞通常有其內部結構和形成方式。例如，我們可以從“dog”“dogs”和“dogcatcher”的字面上推測它們的關係。這些詞都有同一個詞根“dog”，但使用不同的後綴來改變詞的含義。而且，這個關聯可以推廣至其他詞彙。例如，“dog”和“dogs”的關係如同“cat”和“cats”的關係，“boy”和“boyfriend”的關係如同“girl”和“girlfriend”的關係。這一特點並非為英語所獨有。在法語和西班牙語中，很多動詞根據場景不同有40多種不同的形態，而在芬蘭語中，一個名詞可能有15種以上的形態。事實上，構詞學（morphology）作為語言學的一個重要分支，研究的正是詞的內部結構和形成方式。

在word2vec中，我們並沒有直接利用構詞學中的信息。無論是在跳字模型還是連續詞袋模型中，我們都將形態不同的單詞用不同的向量來表示。例如，“dog”和“dogs”分別用兩個不同的向量表示，而模型中並未直接表達這兩個向量之間的關係。鑑於此，fastText提出了子詞嵌入（subword embedding）的方法，從而試圖將構詞信息引入word2vec中的跳字模型 [1]。

在fastText中，每個中心詞被表示成子詞的集合。下面我們用單詞“where”作為例子來了解子詞是如何產生的。首先，我們在單詞的首尾分別添加特殊字符“&lt;”和“&gt;”以區分作為前後綴的子詞。然後，將單詞當成一個由字符構成的序列來提取$n$元語法。例如，當$n=3$時，我們得到所有長度為3的子詞：“&lt;wh&gt;”“whe”“her”“ere”“&lt;re&gt;”以及特殊子詞“&lt;where&gt;”。

在fastText中，對於一個詞$w$，我們將它所有長度在$3 \sim 6$的子詞和特殊子詞的並集記為$\mathcal{G}_w$。那麼詞典則是所有詞的子詞集合的並集。假設詞典中子詞$g$的向量為$\boldsymbol{z}_g$，那麼跳字模型中詞$w$的作為中心詞的向量$\boldsymbol{v}_w$則表示成

$$
\boldsymbol{v}_w = \sum_{g\in\mathcal{G}_w} \boldsymbol{z}_g.
$$

fastText的其餘部分同跳字模型一致，不在此重複。可以看到，與跳字模型相比，fastText中詞典規模更大，造成模型參數更多，同時一個詞的向量需要對所有子詞向量求和，繼而導致計算複雜度更高。但與此同時，較生僻的複雜單詞，甚至是詞典中沒有的單詞，可能會從同它結構類似的其他詞那裡獲取更好的詞向量表示。


## 小結

* fastText提出了子詞嵌入方法。它在word2vec中的跳字模型的基礎上，將中心詞向量表示成單詞的子詞向量之和。
* 子詞嵌入利用構詞上的規律，通常可以提升生僻詞表示的質量。



## 參考文獻

[1] Bojanowski, P., Grave, E., Joulin, A., & Mikolov, T. (2016). Enriching word vectors with subword information. arXiv preprint arXiv:1607.04606.

-----------
> 注：本節與原書完全相同，[原書傳送門](https://zh.d2l.ai/chapter_natural-language-processing/fasttext.html)

