# 5.8 網絡中的網絡（NiN）

前幾節介紹的LeNet、AlexNet和VGG在設計上的共同之處是：先以由卷積層構成的模塊充分抽取空間特徵，再以由全連接層構成的模塊來輸出分類結果。其中，AlexNet和VGG對LeNet的改進主要在於如何對這兩個模塊加寬（增加通道數）和加深。本節我們介紹網絡中的網絡（NiN）[1]。它提出了另外一個思路，即串聯多個由卷積層和“全連接”層構成的小網絡來構建一個深層網絡。


## 5.8.1 NiN塊

我們知道，卷積層的輸入和輸出通常是四維數組（樣本，通道，高，寬），而全連接層的輸入和輸出則通常是二維數組（樣本，特徵）。如果想在全連接層後再接上卷積層，則需要將全連接層的輸出變換為四維。回憶在5.3節（多輸入通道和多輸出通道）裡介紹的$1\times 1$卷積層。它可以看成全連接層，其中空間維度（高和寬）上的每個元素相當於樣本，通道相當於特徵。因此，NiN使用$1\times 1$卷積層來替代全連接層，從而使空間信息能夠自然傳遞到後面的層中去。圖5.7對比了NiN同AlexNet和VGG等網絡在結構上的主要區別。

<div align=center>
<img width="250" src="../img/chapter05/5.8_nin.svg"/>
</div>
<div align=center>圖5.7 左圖是AlexNet和VGG的網絡結構局部，右圖是NiN的網絡結構局部</div>


NiN塊是NiN中的基礎塊。它由一個卷積層加兩個充當全連接層的$1\times 1$卷積層串聯而成。其中第一個卷積層的超參數可以自行設置，而第二和第三個卷積層的超參數一般是固定的。

``` python
import time
import torch
from torch import nn, optim

import sys
sys.path.append("..") 
import d2lzh_pytorch as d2l
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def nin_block(in_channels, out_channels, kernel_size, stride, padding):
    blk = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),
                        nn.ReLU(),
                        nn.Conv2d(out_channels, out_channels, kernel_size=1),
                        nn.ReLU(),
                        nn.Conv2d(out_channels, out_channels, kernel_size=1),
                        nn.ReLU())
    return blk
```

## 5.8.2 NiN模型

NiN是在AlexNet問世不久後提出的。它們的卷積層設定有類似之處。NiN使用卷積窗口形狀分別為$11\times 11$、$5\times 5$和$3\times 3$的卷積層，相應的輸出通道數也與AlexNet中的一致。每個NiN塊後接一個步幅為2、窗口形狀為$3\times 3$的最大池化層。

除使用NiN塊以外，NiN還有一個設計與AlexNet顯著不同：NiN去掉了AlexNet最後的3個全連接層，取而代之地，NiN使用了輸出通道數等於標籤類別數的NiN塊，然後使用全局平均池化層對每個通道中所有元素求平均並直接用於分類。這裡的全局平均池化層即窗口形狀等於輸入空間維形狀的平均池化層。NiN的這個設計的好處是可以顯著減小模型參數尺寸，從而緩解過擬合。然而，該設計有時會造成獲得有效模型的訓練時間的增加。

``` python
# 已保存在d2lzh_pytorch
import torch.nn.functional as F
class GlobalAvgPool2d(nn.Module):
    # 全局平均池化層可通過將池化窗口形狀設置成輸入的高和寬實現
    def __init__(self):
        super(GlobalAvgPool2d, self).__init__()
    def forward(self, x):
        return F.avg_pool2d(x, kernel_size=x.size()[2:])

net = nn.Sequential(
    nin_block(1, 96, kernel_size=11, stride=4, padding=0),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nin_block(96, 256, kernel_size=5, stride=1, padding=2),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nin_block(256, 384, kernel_size=3, stride=1, padding=1),
    nn.MaxPool2d(kernel_size=3, stride=2), 
    nn.Dropout(0.5),
    # 標籤類別數是10
    nin_block(384, 10, kernel_size=3, stride=1, padding=1),
    GlobalAvgPool2d(), 
    # 將四維的輸出轉成二維的輸出，其形狀為(批量大小, 10)
    d2l.FlattenLayer())
```

我們構建一個數據樣本來查看每一層的輸出形狀。

``` python
X = torch.rand(1, 1, 224, 224)
for name, blk in net.named_children(): 
    X = blk(X)
    print(name, 'output shape: ', X.shape)
```
輸出：
```
0 output shape:  torch.Size([1, 96, 54, 54])
1 output shape:  torch.Size([1, 96, 26, 26])
2 output shape:  torch.Size([1, 256, 26, 26])
3 output shape:  torch.Size([1, 256, 12, 12])
4 output shape:  torch.Size([1, 384, 12, 12])
5 output shape:  torch.Size([1, 384, 5, 5])
6 output shape:  torch.Size([1, 384, 5, 5])
7 output shape:  torch.Size([1, 10, 5, 5])
8 output shape:  torch.Size([1, 10, 1, 1])
9 output shape:  torch.Size([1, 10])
```

## 5.8.3 獲取數據和訓練模型

我們依然使用Fashion-MNIST數據集來訓練模型。NiN的訓練與AlexNet和VGG的類似，但這裡使用的學習率更大。

``` python
batch_size = 128
# 如出現“out of memory”的報錯信息，可減小batch_size或resize
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)

lr, num_epochs = 0.002, 5
optimizer = torch.optim.Adam(net.parameters(), lr=lr)
d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)
```
輸出：
```
training on  cuda
epoch 1, loss 0.0101, train acc 0.513, test acc 0.734, time 260.9 sec
epoch 2, loss 0.0050, train acc 0.763, test acc 0.754, time 175.1 sec
epoch 3, loss 0.0041, train acc 0.808, test acc 0.826, time 151.0 sec
epoch 4, loss 0.0037, train acc 0.828, test acc 0.827, time 151.0 sec
epoch 5, loss 0.0034, train acc 0.839, test acc 0.831, time 151.0 sec
```

## 小結

* NiN重複使用由卷積層和代替全連接層的$1\times 1$卷積層構成的NiN塊來構建深層網絡。
* NiN去除了容易造成過擬合的全連接輸出層，而是將其替換成輸出通道數等於標籤類別數的NiN塊和全局平均池化層。
* NiN的以上設計思想影響了後面一系列卷積神經網絡的設計。


## 參考文獻

[1] Lin, M., Chen, Q., & Yan, S. (2013). Network in network. arXiv preprint arXiv:1312.4400.

-----------
> 注：除代碼外本節與原書此節基本相同，[原書傳送門](https://zh.d2l.ai/chapter_convolutional-neural-networks/nin.html)
