# 8.3 自動並行計算

上一節提到，默認情況下，GPU 操作是異步的。當調用一個使用 GPU 的函數時，這些操作會在特定的設備上排隊，但不一定會在稍後執行。這允許我們並行更多的計算，包括 CPU 或其他 GPU 上的操作。
下面看一個簡單的例子。


首先導入本節中實驗所需的包或模塊。注意，需要至少2塊GPU才能運行本節實驗。

``` python
import torch
import time

assert torch.cuda.device_count() >= 2
```

我們先實現一個簡單的計時類。
``` python
class Benchmark():  # 本類已保存在d2lzh_pytorch包中方便以後使用
    def __init__(self, prefix=None):
        self.prefix = prefix + ' ' if prefix else ''

    def __enter__(self):
        self.start = time.time()

    def __exit__(self, *args):
        print('%stime: %.4f sec' % (self.prefix, time.time() - self.start))
```

再定義`run`函數，令它做20000次矩陣乘法。

``` python
def run(x):
    for _ in range(20000):
        y = torch.mm(x, x)
```

接下來，分別在兩塊GPU上創建`Tensor`。

``` python 
x_gpu1 = torch.rand(size=(100, 100), device='cuda:0')
x_gpu2 = torch.rand(size=(100, 100), device='cuda:1')
```

然後，分別使用它們運行`run`函數並打印運行所需時間。

``` python
with Benchmark('Run on GPU1.'):
    run(x_gpu1)
    torch.cuda.synchronize()

with Benchmark('Then run on GPU2.'):
    run(x_gpu2)
    torch.cuda.synchronize()
```

輸出：
```
Run on GPU1. time: 0.2989 sec
Then run on GPU2. time: 0.3518 sec
```

嘗試系統能自動並行這兩個任務：
``` python
with Benchmark('Run on both GPU1 and GPU2 in parallel.'):
    run(x_gpu1)
    run(x_gpu2)
    torch.cuda.synchronize()
```
輸出：
```
Run on both GPU1 and GPU2 in parallel. time: 0.5076 sec
```

可以看到，當兩個計算任務一起執行時，執行總時間小於它們分開執行的總和。這表明，PyTorch能有效地實現在不同設備上自動並行計算。


-----------
> 注：本節與原書有很多不同，[原書傳送門](https://zh.d2l.ai/chapter_computational-performance/auto-parallelism.html)
