# 9.6 目標檢測數據集（皮卡丘）

在目標檢測領域並沒有類似MNIST或Fashion-MNIST那樣的小數據集。為了快速測試模型，我們合成了一個小的數據集。我們首先使用一個開源的皮卡丘3D模型生成了1000張不同角度和大小的皮卡丘圖像。然後我們收集了一系列背景圖像，並在每張圖的隨機位置放置一張隨機的皮卡丘圖像。該數據集使用MXNet提供的im2rec工具將圖像轉換成了二進制的RecordIO格式 [1]。該格式既可以降低數據集在磁盤上的存儲開銷，又能提高讀取效率。如果想了解更多的圖像讀取方法，可以查閱GluonCV工具包的文檔 [2]。


## 9.6.1 下載數據集

前面說了，皮卡丘數據集使用MXNet提供的im2rec工具將圖像轉換成了二進制的RecordIO格式，但是我們後續要使用PyTorch，所以我先用[腳本](https://github.com/ShusenTang/Dive-into-DL-PyTorch/blob/master/code/chapter09_computer-vision/9.6.0_prepare_pikachu.ipynb)將其轉換成了PNG圖片並用json文件存放對應的label信息。在繼續閱讀前，請務必確保運行了這個腳本，保證數據已準備好。`pikachu`文件夾下的結構應如下所示。
```
--pikachu
  --train
    --images
      --1.png
      ...
    --label.json
  --val
    --images
      --1.png
      ...
    --label.json 
```
先導入相關庫。
``` python
%matplotlib inline
import os
import json
import numpy as np
import torch
import torchvision
from PIL import Image

import sys
sys.path.append("..") 
import d2lzh_pytorch as d2l

data_dir = '../../data/pikachu'

assert os.path.exists(os.path.join(data_dir, "train"))
```


## 9.6.2 讀取數據集

我們先定義一個數據集類`PikachuDetDataset`，數據集每個樣本包含`label`和`image`，其中label是一個 $m \times 5$ 的向量，即m個邊界框，每個邊界框由`[class, x_min, y_min, x_max, y_max]`表示，這裡的皮卡丘數據集中每個圖像只有一個邊界框，因此m=1。`image`是一個所有元素都位於`[0.0, 1.0]`的浮點`tensor`，代表圖片數據。
``` python
# 本類已保存在d2lzh_pytorch包中方便以後使用
class PikachuDetDataset(torch.utils.data.Dataset):
    """皮卡丘檢測數據集類"""
    def __init__(self, data_dir, part, image_size=(256, 256)):
        assert part in ["train", "val"]
        self.image_size = image_size
        self.image_dir = os.path.join(data_dir, part, "images")
        
        with open(os.path.join(data_dir, part, "label.json")) as f:
            self.label = json.load(f)
            
        self.transform = torchvision.transforms.Compose([
            # 將 PIL 圖片轉換成位於[0.0, 1.0]的floatTensor, shape (C x H x W)
            torchvision.transforms.ToTensor()])
            
    def __len__(self):
        return len(self.label)
    
    def __getitem__(self, index):
        image_path = str(index + 1) + ".png"
        
        cls = self.label[image_path]["class"]
        label = np.array([cls] + self.label[image_path]["loc"], 
                         dtype="float32")[None, :]
        
        PIL_img = Image.open(os.path.join(self.image_dir, image_path)
                            ).convert('RGB').resize(self.image_size)
        img = self.transform(PIL_img)
        
        sample = {
            "label": label, # shape: (1, 5) [class, xmin, ymin, xmax, ymax]
            "image": img    # shape: (3, *image_size)
        }
        
        return sample
```

然後我們通過創建`DataLoader`實例來讀取目標檢測數據集。我們將以隨機順序讀取訓練數據集，按序讀取測試數據集。
> 原書還做了數據增強: *對於訓練集中的每張圖像，我們將採用隨機裁剪，並要求裁剪出的圖像至少覆蓋每個目標95%的區域。由於裁剪是隨機的，這個要求不一定總被滿足。我們設定最多嘗試200次隨機裁剪：如果都不符合要求則不裁剪圖像。為保證輸出結果的確定性，我們不隨機裁剪測試數據集中的圖像。 我們也無須按隨機順序讀取測試數據集。*

``` python
# 本函數已保存在d2lzh_pytorch包中方便以後使用
def load_data_pikachu(batch_size, edge_size=256, data_dir = '../../data/pikachu'):  
    """edge_size：輸出圖像的寬和高"""
    image_size = (edge_size, edge_size)
    train_dataset = PikachuDetDataset(data_dir, 'train', image_size)
    val_dataset = PikachuDetDataset(data_dir, 'val', image_size)
    

    train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, 
                                             shuffle=True, num_workers=4)

    val_iter = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,
                                           shuffle=False, num_workers=4)
    return train_iter, val_iter
```

下面我們讀取一個小批量並打印圖像和標籤的形狀。圖像的形狀和之前實驗中的一樣，依然是(批量大小, 通道數, 高, 寬)。而標籤的形狀則是(批量大小, $m$, 5)，其中$m$等於數據集中單個圖像最多含有的邊界框個數。小批量計算雖然高效，但它要求每張圖像含有相同數量的邊界框，以便放在同一個批量中。由於每張圖像含有的邊界框個數可能不同，我們為邊界框個數小於$m$的圖像填充非法邊界框，直到每張圖像均含有$m$個邊界框。這樣，我們就可以每次讀取小批量的圖像了。圖像中每個邊界框的標籤由長度為5的數組表示。數組中第一個元素是邊界框所含目標的類別。當值為-1時，該邊界框為填充用的非法邊界框。數組的剩餘4個元素分別表示邊界框左上角的$x$和$y$軸座標以及右下角的$x$和$y$軸座標（值域在0到1之間）。這裡的皮卡丘數據集中每個圖像只有一個邊界框，因此$m=1$。

``` python
batch_size, edge_size = 32, 256
train_iter, _ = load_data_pikachu(batch_size, edge_size, data_dir)
batch = iter(train_iter).next()
print(batch["image"].shape, batch["label"].shape)
```
輸出：
```
torch.Size([32, 3, 256, 256]) torch.Size([32, 1, 5])
```

## 9.6.3 圖示數據

我們畫出10張圖像和它們中的邊界框。可以看到，皮卡丘的角度、大小和位置在每張圖像中都不一樣。當然，這是一個簡單的人工數據集。實際中的數據通常會複雜得多。

``` python
imgs = batch["image"][0:10].permute(0,2,3,1)
bboxes = batch["label"][0:10, 0, 1:]

axes = d2l.show_images(imgs, 2, 5).flatten()
for ax, bb in zip(axes, bboxes):
    d2l.show_bboxes(ax, [bb*edge_size], colors=['w'])
```
<div align=center>
<img width="600" src="../img/chapter09/9.6_output1.png"/>
</div>

## 小結

* 合成的皮卡丘數據集可用於測試目標檢測模型。
* 目標檢測的數據讀取跟圖像分類的類似。然而，在引入邊界框後，標籤形狀和圖像增廣（如隨機裁剪）發生了變化。


## 參考文獻

[1] im2rec工具。https://github.com/apache/incubator-mxnet/blob/master/tools/im2rec.py

[2] GluonCV 工具包。https://gluon-cv.mxnet.io/

-----------
> 注：除代碼外本節與原書基本相同，[原書傳送門](http://zh.d2l.ai/chapter_computer-vision/object-detection-dataset.html)
